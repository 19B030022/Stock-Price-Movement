{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhfk2bBQ3SPL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from textblob import TextBlob  # Sentiment analysis library\n",
        "\n",
        "# Load your stock price data (e.g., historical closing prices) and sentiment analysis data\n",
        "# Ensure your data includes a date or timestamp column\n",
        "# Preprocess your data as needed\n",
        "\n",
        "# Example sentiment analysis function using TextBlob\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity\n",
        "\n",
        "# Apply sentiment analysis to your dataset\n",
        "# Replace 'text_column' with the column containing text data\n",
        "# Create a new column 'sentiment' to store sentiment scores\n",
        "# Example: df['sentiment'] = df['text_column'].apply(get_sentiment)\n",
        "\n",
        "# Combine and preprocess your data as needed\n",
        "\n",
        "# Split your data into training and testing sets\n",
        "train_size = int(len(data) * 0.8)\n",
        "train_data = data[:train_size]\n",
        "test_data = data[train_size:]\n",
        "\n",
        "# Normalize your data using Min-Max scaling\n",
        "scaler = MinMaxScaler()\n",
        "train_data = scaler.fit_transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "\n",
        "# Define hyperparameters\n",
        "sequence_length = 10\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "# Create sequences for training and testing\n",
        "def create_sequences(data, sequence_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        seq = data[i:i+sequence_length]\n",
        "        target = data[i+sequence_length]\n",
        "        sequences.append((seq, target))\n",
        "    return np.array(sequences)\n",
        "\n",
        "train_sequences = create_sequences(train_data, sequence_length)\n",
        "test_sequences = create_sequences(test_data, sequence_length)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(sequence_length, num_features), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_sequences[:, 0], train_sequences[:, 1], batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "predicted_stock_prices = model.predict(test_sequences[:, 0])\n",
        "predicted_stock_prices = scaler.inverse_transform(predicted_stock_prices)\n",
        "actual_stock_prices = scaler.inverse_transform(test_sequences[:, 1])\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(actual_stock_prices, label='Actual Prices')\n",
        "plt.plot(predicted_stock_prices, label='Predicted Prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ]
}